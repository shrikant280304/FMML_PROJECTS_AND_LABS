{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrikant280304/FMML_PROJECTS_AND_LABS/blob/main/FMML_Module_3_project_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unG213zJhFsx"
      },
      "source": [
        "# **FOUNDATIONS OF MODERN MACHINE LEARNING, IIIT Hyderabad**\n",
        "# Project : Data Visualization, Choosing K-value and Appreciating Feature Scaling and Standardization\n",
        "## Module Coordinator: Jashn Arora\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "1YbIjlgrhFsz"
      },
      "source": [
        "## Binary Classification Task: Diabetes Dataset\n",
        "\n",
        "Weâ€™ll be using ML techniques learnt uptil now to predict whether a Pima Indian Woman has diabetes or not, based on information about the patient such as blood pressure, body mass index (BMI), age, etc.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcQGSOFchFs0"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Scientists carried out a study to investigate the significance of health-related predictors of diabetes in **Pima Indian Women**. The study population was females (21 years and above) of Pima Indian heritage.\n",
        "\n",
        "The purpose of the study was to find out the factors that are associated with the presence of diabetes in Pima Indians.\n",
        "\n",
        "To find out the reason behind this, we have to first analyze the relationship between different features, such as the number of times a woman was pregnant, their BMI, prevalence of diabetes, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQIjzjdvhFs1"
      },
      "source": [
        "## Exploratory Data Analysis (EDA) and Statistical Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBuD7M7yhFs1"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-61IRwW9hFs2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PsuSvHBhFs2"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "su9YeUtjx7Vt",
        "outputId": "857c371e-bf93-49dd-fdba-f4e5d4c49d5c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e7715974-f6bf-4d79-973d-7762019beb4f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e7715974-f6bf-4d79-973d-7762019beb4f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Upload the preprocessed diabetes data CSV file that has been shared with you.\n",
        "# Run this cell, click on the 'Choose files' button and upload the file.\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jD3AJ4bMhFs2"
      },
      "outputs": [],
      "source": [
        "diabetes_data = pd.read_csv('preprocessed_diabetes_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHXBgngihFs3"
      },
      "outputs": [],
      "source": [
        "# View top 10 rows of the Diabetes dataset\n",
        "diabetes_data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp-JWCiPhFs3"
      },
      "source": [
        "## Identification of variables and data types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxb4gUfwhFs3"
      },
      "outputs": [],
      "source": [
        "diabetes_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5arc6ZbOhFs3"
      },
      "source": [
        "Dataset comprises of 768 observations and 9 fields.\n",
        "\n",
        "The following features have been provided to help us predict whether a person is diabetic or not:\n",
        "\n",
        "* **Pregnancies:** Number of times pregnant\n",
        "* **Glucose:** Plasma glucose concentration over 2 hours in an oral glucose tolerance test. Less than 140 mg/dL is considered normal level of glucose.\n",
        "* **BloodPressure:** Diastolic blood pressure (mm Hg). 120/80 is normal BP level for females above 18 years old.\n",
        "* **SkinThickness:** Triceps skin fold thickness (mm)\n",
        "* **Insulin:** 2-Hour serum insulin (mu U/ml). 16-166 mIU/L is considered the normal level of insulin.\n",
        "* **BMI:** Body mass index (weight in kg/((height in m$)^2$))\n",
        "* **DiabetesPedigreeFunction:** Diabetes pedigree function (a function which scores likelihood of diabetes based on family history)\n",
        "* **Age:** Age (in years)\n",
        "* **Outcome:** Class variable (0 if non-diabetic, 1 if diabetic)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKH8cPIBhFs4"
      },
      "outputs": [],
      "source": [
        "# Get the details of each column\n",
        "diabetes_data.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v_JcMPYhFs6"
      },
      "source": [
        "Let us see distribution and also boxplot for outliers of feature \"Pregnancies\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh9KHJcEhFs6"
      },
      "outputs": [],
      "source": [
        "fig,axes = plt.subplots(nrows=1,ncols=2,figsize = (8,6))\n",
        "\n",
        "plot00=sns.distplot(diabetes_data['Pregnancies'],ax=axes[0],color='b')\n",
        "axes[0].set_title('Distribution of Pregnancy',fontdict={'fontsize':8})\n",
        "axes[0].set_xlabel('No of Pregnancies')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "plot01=sns.boxplot(data=diabetes_data['Pregnancies'], ax=axes[1],orient = 'v', color='r')\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZISBYEz7jwv"
      },
      "outputs": [],
      "source": [
        "## TASK-1 :\n",
        "## Find out the \"Correlation\" between the different attributes present in the data.\n",
        "## Also plot a heatmap (refer Seaborn documentation) for the correlation values obtained.\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "diabetes_data = pd.read_csv('preprocessed_diabetes_data.csv')\n",
        "\n",
        "# Display the first few rows of the DataFrame (optional)\n",
        "print(diabetes_data.head())\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = diabetes_data.corr()\n",
        "\n",
        "# Plotting the heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
        "plt.title('Correlation Heatmap of Diabetes Attributes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deFQgd6ZZxdd"
      },
      "outputs": [],
      "source": [
        "diabetes_data.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnRYznyBhFs8"
      },
      "source": [
        "<p style=\"font-weight: bold;color:#FF4500\"><b>Observations</b></p>  \n",
        "\n",
        "* From the correlation map you just obtained above, it seems that Insulin is highly correlated with Glucose, BMI and Age. It means that as the values of glucose, BMI and Age increase, the insulin is also increasing. It seems logical also that overweight and elderly people might have a higher level of insulin in their bodies.  \n",
        "\n",
        "* In the same way SkinThickness is highly correlated with BMI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibQhQ3qihFs-"
      },
      "source": [
        "## Checking  if the data is balanced or imbalanced\n",
        "\n",
        "We can produce a seaborn count plot to check if the output is dominated by one of the classes or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Vo4IoVfhFs-"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.countplot(x='Outcome',data=diabetes_data, palette='bright')\n",
        "plt.title(\"Output class distribution\")\n",
        "\n",
        "print(diabetes_data['Outcome'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsO1fRfGhFs_"
      },
      "source": [
        "<p style=\"font-weight: bold;color:#FF4500\"><b>Observations</b></p>  \n",
        "\n",
        "A total of 768 women were registered in the database. 268 women had diabetes, while 500 women did not have diabetes.\n",
        "\n",
        "The above graph shows that the dataset is biased towards non-diabetic people. The number of non-diabetic people is almost twice the number of diabetic patients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLZVGWpUhFs_"
      },
      "source": [
        "## Scatter matrix of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqCv0o359ydE"
      },
      "source": [
        "A pair-plot builds on two basic figures, the histogram and the scatter plot. The histogram on the diagonal allows us to see the distribution of a single variable while the scatter plots on the upper and lower triangles show the relationship (or lack thereof) between two variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXD7RCUjhFs_"
      },
      "outputs": [],
      "source": [
        "## TASK-2: Display a pairplot using Seaborn for the diabetes dataset, with the 'outcome' as the hue.\n",
        "\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "diabetes_data = pd.read_csv('preprocessed_diabetes_data.csv')\n",
        "\n",
        "# Pairplot using Seaborn with 'Outcome' as the hue\n",
        "sns.pairplot(diabetes_data, hue='Outcome', palette='bright')\n",
        "plt.suptitle(\"Pairplot of Diabetes Dataset\", y=1.02)  # Adjust title position\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyIfVZGz-AVA"
      },
      "source": [
        "## BMI vs Outcome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1C9GazEwhFtA"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.boxplot(x='Outcome', y='BMI',data=diabetes_data, hue='Outcome')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zeDFUjIhFtA"
      },
      "source": [
        "<p style=\"font-weight: bold;color:#FF4500\"><b>Observations</b></p>\n",
        "\n",
        "It is surprising that the median BMI does not significanty change as the number of pregnancies increases. Those who tested positive for diabetes had higher BMIs than those who did not. However,there is not a very large difference between the medians.\n",
        "\n",
        "BMI might be higher for women who have had more numbers of pregnancies as well as for those who test positive for diabetes and that the relationship between the pedigree function and the test results will show that those who had a higher pedigree function tested positive and those who had a lower pedigree function tested negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TVSVM2qhFtA"
      },
      "source": [
        "## Pedigree function vs Diabetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96GqOonO-bkE"
      },
      "outputs": [],
      "source": [
        "## TASK-3: Display a boxplot between the Pedigree function and Diabetes.\n",
        "\n",
        "diabetes_data = pd.read_csv('preprocessed_diabetes_data.csv')\n",
        "\n",
        "# Check the column names\n",
        "print(diabetes_data.columns)\n",
        "\n",
        "# Assuming the correct column name is 'DiabetesPedigreeFunction'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Outcome', y='DiabetesPedigreeFunction', data=diabetes_data, palette='bright')\n",
        "plt.title(\"Boxplot of Diabetes Pedigree Function by Diabetes Outcome\")\n",
        "plt.xlabel(\"Diabetes Outcome (0 = No, 1 = Yes)\")\n",
        "plt.ylabel(\"Diabetes Pedigree Function\")\n",
        "plt.xticks([0, 1], ['No Diabetes', 'Diabetes'])  # Labeling the x-axis\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnRxDLryhFtB"
      },
      "source": [
        "<p style=\"font-weight: bold;color:#FF4500\"><b>Observations</b></p>\n",
        "This graph more clearly shows the relationship between the pedigree function and the test results that the women got for diabetes. Since those who tested positive have a higher median and more high outliers, it is clear that the pedigree function does in fact, accurately help estimate the test results for diabetes. It shows that diabetes does follow genetics so those whose ancestors suffered from it have a higher risk of getting the disease themselves as well. Both test results show many outliers yet the outliers for those who tested negative seem to have lower pedigree functions than those who tested positive. This indicates that the genetic component is likely to contribute more to the emergence of diabetes in the Pima Indians and their offspring."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Haicc9d0hFtB"
      },
      "source": [
        "## Pregnancy vs Diabetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_x36kL5_Iyt"
      },
      "outputs": [],
      "source": [
        "## TASK-4: Display a boxplot between the number of Pregnancies and Diabetes.\n",
        "# Load the dataset\n",
        "data = pd.read_csv('preprocessed_diabetes_data.csv')\n",
        "\n",
        "# Check the column names and the first few rows of the dataset\n",
        "print(data.columns)  # Print column names\n",
        "print(data.head())   # Print the first few rows\n",
        "\n",
        "# Create the boxplot using 'Outcome' instead of 'Diabetes'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Pregnancies', y='Outcome', data=data)\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Number of Pregnancies')\n",
        "plt.ylabel('Diabetes Status (Outcome)')\n",
        "plt.title('Boxplot of Number of Pregnancies vs. Diabetes Outcome')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR5LPr3phFtC"
      },
      "source": [
        "<p style=\"font-weight: bold;color:#FF4500\"><b>Observations</b></p>\n",
        "\n",
        "The average number of pregnancies is higher in diabetic as compared to non-diabetic women."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmvNQIOFhFtC"
      },
      "source": [
        "## Prevalence of Diabetes vs BMI\n",
        "\n",
        "Let's try to find out the prevalence of diabetes and its relation to their BMI. Please note that the range of normal BMI is 18.5 to 25."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kCMTdmGhFtC"
      },
      "outputs": [],
      "source": [
        "normalBMIData = diabetes_data[(diabetes_data['BMI'] >= 18.5) & (diabetes_data['BMI'] <= 25)]\n",
        "normalBMIData['Outcome'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z--JC25ehFtC"
      },
      "outputs": [],
      "source": [
        "notNormalBMIData = diabetes_data[(diabetes_data['BMI'] < 18.5) | (diabetes_data['BMI'] > 25)]\n",
        "notNormalBMIData['Outcome'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrdJR1wkhFtD"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.boxplot(x='Outcome', y='BMI',data=notNormalBMIData)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8D7KzjphFtD"
      },
      "source": [
        "<p style=\"font-weight: bold;color:#FF4500\"><b>Observations</b></p>\n",
        "\n",
        "The Body Mass Index (BMI) shows a significant association with the occurrence of diabetes.  \n",
        "The interquartile range for the women who tested positive reaches a higher BMI than the IQR for those who tested negative. Therefore, women could have higher BMIs and not be outliers if they tested positive as opposed to negative, showing that more women who tested positive did, in fact, have higher BMIs than those who tested negative.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1_nVeb8hFtD"
      },
      "source": [
        "## Age vs Diabetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-s-5gavNAf0m"
      },
      "outputs": [],
      "source": [
        "## TASK-5: Display a boxplot between Age and Diabetes.\n",
        "data = pd.read_csv('preprocessed_diabetes_data.csv')\n",
        "\n",
        "# Check the column names and the first few rows of the dataset (optional)\n",
        "print(data.columns)  # Print column names\n",
        "print(data.head())   # Print the first few rows\n",
        "\n",
        "# Create the boxplot for Age and Diabetes Outcome\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Outcome', y='Age', data=data)\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Diabetes Status (Outcome)')\n",
        "plt.ylabel('Age')\n",
        "plt.title('Boxplot of Age vs. Diabetes Outcome')\n",
        "plt.xticks([0, 1], ['No Diabetes (0)', 'Diabetes (1)'])  # Custom x-tick labels\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skK67P9mhFtE"
      },
      "source": [
        "<p style=\"font-weight: bold;color:#FF4500\"><b>Observations</b></p>  \n",
        "\n",
        "A significant relation can be seen between the age distribution and occurrence of diabetes. Women at age group > 31 years were at higher risk of getting diabetes in comparison to the younger age group."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKo2iJYbhFtE"
      },
      "source": [
        "# The Importance of Standardizing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfNzaXgJhFtF"
      },
      "outputs": [],
      "source": [
        "unchanged_data = diabetes_data.drop('Outcome',axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69yA8N2xp8w-"
      },
      "outputs": [],
      "source": [
        "unchanged_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j78tjiVkhFtG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_lGuVYyI0wj"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0AsnKb-hFtI"
      },
      "source": [
        "# Choosing a K Value\n",
        "Let's go ahead and use the elbow method to pick a good K Value!\n",
        "\n",
        "*Create a for loop that trains various KNN models with different k values, then keep track of the error_rate for each of these models with a list.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Answer to Task-6. Refer to and run this only if you are unable to complete the task in the previous cell.\n",
        "def plot_KNN_error_rate(xdata,ydata):\n",
        "  error_rate = []\n",
        "  test_scores = []\n",
        "  train_scores = []\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(xdata, ydata, test_size=0.3, random_state=101)\n",
        "\n",
        "  for i in range(1,40):\n",
        "      knn = KNeighborsClassifier(n_neighbors=i)\n",
        "      knn.fit(X_train, y_train)\n",
        "      pred_i = knn.predict(X_test)\n",
        "\n",
        "      error_rate.append(np.mean(pred_i != y_test))\n",
        "      train_scores.append(knn.score(X_train,y_train))\n",
        "      test_scores.append(knn.score(X_test,y_test))\n",
        "\n",
        "  plt.figure(figsize=(12,8))\n",
        "  plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
        "          markerfacecolor='red', markersize=10)\n",
        "  plt.title('Error Rate vs. K Value')\n",
        "  plt.xlabel('K')\n",
        "  plt.ylabel('Error Rate')\n",
        "  print()\n",
        "  ## score that comes from testing on the same datapoints that were used for training\n",
        "  max_train_score = max(train_scores)\n",
        "  train_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\n",
        "  print('Max train score {} % and k = {}'.format(max_train_score*100,list(map(lambda x: x+1, train_scores_ind))))\n",
        "  print()\n",
        "  ## score that comes from testing on the datapoints that were split in the beginning to be used for testing solely\n",
        "  max_test_score = max(test_scores)\n",
        "  test_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\n",
        "  print('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))\n",
        "\n",
        "  return test_scores"
      ],
      "metadata": {
        "id": "yEn84AVPr0-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xm8uwN1ZC7hp"
      },
      "outputs": [],
      "source": [
        "#@title Answer to Task-6. Refer to and run this only if you are unable to complete the task in the previous cell.\n",
        "def plot_KNN_error_rate(xdata,ydata):\n",
        "  error_rate = []\n",
        "  test_scores = []\n",
        "  train_scores = []\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(xdata, ydata, test_size=0.3, random_state=101)\n",
        "\n",
        "  for i in range(1,40):\n",
        "      knn = KNeighborsClassifier(n_neighbors=i)\n",
        "      knn.fit(X_train, y_train)\n",
        "      pred_i = knn.predict(X_test)\n",
        "\n",
        "      error_rate.append(np.mean(pred_i != y_test))\n",
        "      train_scores.append(knn.score(X_train,y_train))\n",
        "      test_scores.append(knn.score(X_test,y_test))\n",
        "\n",
        "  plt.figure(figsize=(12,8))\n",
        "  plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
        "          markerfacecolor='red', markersize=10)\n",
        "  plt.title('Error Rate vs. K Value')\n",
        "  plt.xlabel('K')\n",
        "  plt.ylabel('Error Rate')\n",
        "  print()\n",
        "  ## score that comes from testing on the same datapoints that were used for training\n",
        "  max_train_score = max(train_scores)\n",
        "  train_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\n",
        "  print('Max train score {} % and k = {}'.format(max_train_score*100,list(map(lambda x: x+1, train_scores_ind))))\n",
        "  print()\n",
        "  ## score that comes from testing on the datapoints that were split in the beginning to be used for testing solely\n",
        "  max_test_score = max(test_scores)\n",
        "  test_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\n",
        "  print('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))\n",
        "\n",
        "  return test_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Rj96qrEOKVw"
      },
      "outputs": [],
      "source": [
        "unchanged_test_scores = plot_KNN_error_rate(unchanged_data,diabetes_data['Outcome'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OZFsqr1hFtE"
      },
      "source": [
        "## Standardize the Variables\n",
        "Standardization (also called z-score normalization) is the process of putting different variables on the same scale. Standardization transforms your data such that the resulting distribution has a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "$$ Z = {X - \\mu \\over \\sigma}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgZdXekchFtE"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hyAXJ_vhFtF"
      },
      "outputs": [],
      "source": [
        "scaler.fit(diabetes_data.drop('Outcome',axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6dMR3MJFFdA"
      },
      "outputs": [],
      "source": [
        "scaled_data = scaler.transform(diabetes_data.drop('Outcome',axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFANLGLuhFtF"
      },
      "outputs": [],
      "source": [
        "df_feat = pd.DataFrame(scaled_data,columns=diabetes_data.columns[:-1])\n",
        "df_feat.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwuhzRarQRRQ"
      },
      "outputs": [],
      "source": [
        "scaled_test_scores = plot_KNN_error_rate(scaled_data,diabetes_data['Outcome'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoBBRF8FRkrV"
      },
      "source": [
        "## Comparing Accuracy before and after Standardization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9uVwaaBQ7RE"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "plt.title('Accuracy vs. K Value')\n",
        "sns.lineplot(unchanged_test_scores,marker='o',label='Unscaled data test score')\n",
        "sns.lineplot(scaled_test_scores,marker='o',label='Scaled data test Score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJeZOI-KFKTU"
      },
      "outputs": [],
      "source": [
        "## TASK-7: Refer to MinMax Scaler provided in scikit-learn.\n",
        "## Use MinMax scaling on the dataset, and see the performance of KNN on this minmax-scaled dataset.\n",
        "data = pd.read_csv('preprocessed_diabetes_data.csv')\n",
        "\n",
        "# Check the data\n",
        "print(\"Column names:\", data.columns.tolist())  # Print column names as a list\n",
        "print(\"First few rows of the dataset:\\n\", data.head())  # Print first few rows\n",
        "\n",
        "# Step 3: Preprocess the data\n",
        "target_column = 'Outcome'  # Replace with your actual target column name\n",
        "X = data.drop(columns=[target_column])  # Features\n",
        "y = data[target_column]  # Target\n",
        "\n",
        "# Step 4: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Apply MinMax scaling\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 6: Train the KNN model\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 7: Evaluate performance\n",
        "y_pred = knn.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy of KNN on MinMax scaled dataset: {accuracy:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKQrb8zjTJ_t"
      },
      "outputs": [],
      "source": [
        "## TASK-8:\n",
        "## Plot the voronoi diagram for the TASK-7\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv('preprocessed_diabetes_data.csv')\n",
        "\n",
        "# Check the data\n",
        "print(\"Column names:\", data.columns.tolist())  # Print column names as a list\n",
        "print(\"First few rows of the dataset:\\n\", data.head())  # Print first few rows\n",
        "\n",
        "# Preprocess the data\n",
        "target_column = 'Outcome'  # Update this to your actual target column name\n",
        "X = data.drop(columns=[target_column])  # Features\n",
        "y = data[target_column]  # Target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply MinMax scaling\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the KNN model\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate performance\n",
        "y_pred = knn.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy of KNN on MinMax scaled dataset: {accuracy:.2f}')\n",
        "\n",
        "# Step to plot Voronoi Diagram\n",
        "# We will use only two features for a 2D plot\n",
        "# Select two features from X for plotting\n",
        "# Ensure to choose appropriate feature indices for visualization\n",
        "X_train_2d = X_train_scaled[:, :2]  # Use the first two features for 2D visualization\n",
        "\n",
        "# Create Voronoi diagram\n",
        "vor = Voronoi(X_train_2d)\n",
        "\n",
        "# Plotting\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "voronoi_plot_2d(vor, ax=ax, show_vertices=False, line_colors='orange', line_width=2, fill=False)\n",
        "\n",
        "# Plot training points\n",
        "scatter = ax.scatter(X_train_2d[:, 0], X_train_2d[:, 1], c=y_train, s=50, cmap='viridis', edgecolor='k')\n",
        "\n",
        "# Set title and labels\n",
        "ax.set_title('Voronoi Diagram for KNN Classifier', fontsize=16)\n",
        "ax.set_xlabel('Feature 1', fontsize=14)\n",
        "ax.set_ylabel('Feature 2', fontsize=14)\n",
        "\n",
        "# Add legend\n",
        "handles, labels = scatter.legend_elements()\n",
        "legend = ax.legend(handles, labels, title=\"Classes\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBzds9_dFmgz"
      },
      "outputs": [],
      "source": [
        "## TASK-9: Use K-Fold cross validation on all the above classification experiments and present an analysis of the results you obtain.\n",
        "\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv('preprocessed_diabetes_data.csv')\n",
        "\n",
        "# Check the data\n",
        "print(\"Column names:\", data.columns.tolist())  # Print column names as a list\n",
        "print(\"First few rows of the dataset:\\n\", data.head())  # Print first few rows\n",
        "\n",
        "# Preprocess the data\n",
        "target_column = 'Outcome'  # Update this to your actual target column name\n",
        "X = data.drop(columns=[target_column])  # Features\n",
        "y = data[target_column]  # Target\n",
        "\n",
        "# Apply MinMax scaling\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Set up K-Fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold cross-validation\n",
        "\n",
        "# Prepare to collect accuracy scores\n",
        "accuracy_scores = []\n",
        "\n",
        "# Perform K-Fold cross-validation\n",
        "for train_index, test_index in kf.split(X_scaled):\n",
        "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Train the KNN model\n",
        "    knn = KNeighborsClassifier(n_neighbors=3)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate performance\n",
        "    y_pred = knn.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_scores.append(accuracy)\n",
        "\n",
        "# Analyze the results\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "\n",
        "print(f'Accuracy scores for each fold: {accuracy_scores}')\n",
        "print(f'Mean Accuracy: {mean_accuracy:.2f}')\n",
        "print(f'Standard Deviation of Accuracy: {std_accuracy:.2f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj2xeXZthFtM"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "From the data analysis we carried out, it seems that there is some form of an association between BMI, number of pregnancies, pedigree function, and the test results for diabetes.\n",
        "\n",
        "As for the classification tasks, the standardized data yields much better results than the unscaled data over most of the K-values considered, thus indicating the importance of standardizing data in Machine Learning problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aubGhsTSjJLM"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XehDqRkdjN0_"
      },
      "source": [
        "https://www.kaggle.com/dktalaicha/diabetes-prediction-by-knn"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}